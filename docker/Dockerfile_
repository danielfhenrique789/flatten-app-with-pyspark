FROM bitnami/spark:3.5.5

# Set environment variables
ENV SPARK_HOME=/opt/bitnami/spark
ENV PATH="$SPARK_HOME/bin:$PATH"
ENV SPARK_MASTER_URL=spark://spark-master:7077
ENV SPARK_LOCAL_DIRS=/tmp
ENV SPARK_WORKER_DIR=/tmp
ENV HADOOP_USER_NAME=root
ENV SPARK_USER=root
ENV HADOOP_CONF_DIR=/opt/bitnami/spark/conf
#ENV SPARK_OPTS=--conf spark.hadoop.security.authentication=none

# Create a writable directory for PySpark dependencies
RUN mkdir -p /tmp/.ivy2 && chmod -R 777 /tmp/.ivy2

# Install PySpark (Python is already included in the Bitnami image)
RUN pip install --upgrade pip && pip install pyspark

# Set working directory
WORKDIR /app

# Copy application files
COPY src/ src/
COPY config/ config/
COPY config/core-site.xml /opt/bitnami/spark/conf/core-site.xml

# Set an entrypoint to ensure shell interpretation
#ENTRYPOINT ["/bin/bash", "-c"]
#ENTRYPOINT ["/opt/bitnami/spark/bin/spark-submit", "/app/src/main.py"]
#CMD ["/opt/bitnami/spark/bin/spark-submit", "--master", "local[*]", "/app/src/main.py"]


