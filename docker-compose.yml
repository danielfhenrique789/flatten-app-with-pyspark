services:
  pyspark-app:
    build:
      context: .
      dockerfile: docker/Dockerfile
    working_dir: /app
    volumes:
      - ./config:/app/config
      - ./src:/app/src
      - ./data:/app/data
      - ./scripts:/app/scripts
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - HOME=/opt/bitnami
      - SPARK_LOCAL_DIRS=/tmp
      - SPARK_WORKER_DIR=/tmp
      - HADOOP_USER_NAME=root
      - SPARK_USER=root
      - HADOOP_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_JARS_IVY=/tmp/.ivy2
      - SPARK_OPTS=--conf spark.hadoop.security.authentication=simple
    networks:
      - flatten_app_network
    ports:
      - "4040:4040"
    entrypoint: ["bash", "scripts/sh/run_spark.sh"]

  pyspark-app-test:
    build:
      context: .
      dockerfile: docker/Dockerfile
    working_dir: /app
    volumes:
      - ./config:/app/config
      - ./src:/app/src
      - ./tests:/app/tests
      - ./data:/app/data
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - HOME=/opt/bitnami
      - SPARK_LOCAL_DIRS=/tmp
      - SPARK_WORKER_DIR=/tmp
      - HADOOP_USER_NAME=root
      - SPARK_USER=root
      - HADOOP_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_JARS_IVY=/tmp/.ivy2
      - SPARK_OPTS=--conf spark.hadoop.security.authentication=simple
      - PYTHONPATH=src
    networks:
      - flatten_app_network
    ports:
      - "4040:4040"
    entrypoint: ["pytest", "tests/"]

networks:
  flatten_app_network:
    driver: bridge